version: '3.8'

services:
  # MongoDB Database
  mongodb:
    image: mongo:6.0
    container_name: me-core-mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:-password}
      MONGO_INITDB_DATABASE: marker_engine
    volumes:
      - mongodb_data:/data/db
      - ./backend/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    networks:
      - me-core-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: me-core-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - me-core-network

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: me-core-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: mongodb://admin:${MONGO_PASSWORD:-password}@mongodb:27017/marker_engine?authSource=admin
      MONGO_DB_NAME: marker_engine
      REDIS_URL: redis://redis:6379/0
      SPARK_NLP_ENABLED: ${SPARK_NLP_ENABLED:-false}
      CACHE_TYPE: redis
      ENABLE_METRICS: true
    volumes:
      - ./backend:/app
      - backend_logs:/app/logs
    depends_on:
      - mongodb
      - redis
    networks:
      - me-core-network
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Spark NLP Service (optional)
  spark-nlp:
    build:
      context: ./spark-nlp
      dockerfile: docker/Dockerfile
    container_name: me-core-spark
    restart: unless-stopped
    ports:
      - "4040:4040"  # Spark UI
      - "8090:8090"  # Custom service port
    environment:
      SPARK_DRIVER_MEMORY: ${SPARK_DRIVER_MEMORY:-4g}
      SPARK_EXECUTOR_MEMORY: ${SPARK_EXECUTOR_MEMORY:-2g}
      MONGODB_URI: mongodb://admin:${MONGO_PASSWORD:-password}@mongodb:27017/marker_engine?authSource=admin
    volumes:
      - ./spark-nlp/src:/app/src
      - spark_logs:/app/logs
    depends_on:
      - mongodb
    networks:
      - me-core-network
    profiles:
      - spark

  # Frontend Next.js App
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${API_URL:-http://localhost:8000}
    container_name: me-core-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      NEXT_PUBLIC_API_URL: ${API_URL:-http://backend:8000}
      NODE_ENV: ${NODE_ENV:-development}
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - backend
    networks:
      - me-core-network
    command: npm run dev

  # Prometheus for Metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: me-core-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - me-core-network
    profiles:
      - monitoring

  # Grafana for Dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: me-core-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    networks:
      - me-core-network
    profiles:
      - monitoring

  # Nginx Reverse Proxy (Production)
  nginx:
    image: nginx:alpine
    container_name: me-core-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
      - frontend
    networks:
      - me-core-network
    profiles:
      - production

networks:
  me-core-network:
    driver: bridge

volumes:
  mongodb_data:
  redis_data:
  backend_logs:
  spark_logs:
  prometheus_data:
  grafana_data: