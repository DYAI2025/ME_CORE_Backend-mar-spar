# ME_CORE_Backend-mar-spar

**MarkerEngine Core Backend Monorepo** - Ein schlankes Monorepo fÃ¼r Backend-, Spark- und Frontend-Komponenten mit einheitlichem Release- und Testprozess.

## ğŸ—ï¸ Monorepo-Struktur

```
/ME_CORE_Backend-mar-spar/
â”‚
â”œâ”€ .github/                # GitHub Actions / Issue-Vorlagen
â”œâ”€ jenkins/                # Jenkins-Pipeline-Definitions
â”œâ”€ docs/                   # Architektur-, API- und Deploy-Dokumentation
â”œâ”€ tools/                  # Hilfsskripte (z.B. Schema-Generator)
â”‚
â”œâ”€ backend/                # Aus _1-_MEWT-backend
â”‚   â”œâ”€ api/                # FastAPI-Router fÃ¼r Analyse & Schemas
â”‚   â”œâ”€ detect/             # Detector-Registry & Module
â”‚   â”œâ”€ scoring/            # Score-Engine & Profile
â”‚   â”œâ”€ calculate/          # Baseline-Calculator
â”‚   â”œâ”€ markers/            # Marker-Definitionen (yaml + json)
â”‚   â””â”€ schemata/           # JSON-Schemas (v2.1 + enhanced master)
â”‚
â”œâ”€ spark-nlp/              # Aus markerengine-spark-nlp
â”‚   â”œâ”€ src/                # Spark-Jobs, UDF-Registrierung
â”‚   â”œâ”€ docker/             # Docker-Definitionen
â”‚   â””â”€ tests/              # Integrationstests fÃ¼r Spark-Pipeline
â”‚
â””â”€ frontend/               # Aus markerengine_frontend
    â”œâ”€ src/                # Next.js-App
    â”œâ”€ public/             # Statische Assets
    â””â”€ tests/              # UI- und API-Stubs-Tests
```

## ğŸš€ Quick Start

### Voraussetzungen

- Python 3.10+
- Node.js 18+
- Java 11 (fÃ¼r Spark NLP)
- Docker & Docker Compose
- MongoDB

### Installation

```bash
# Repository klonen
git clone https://github.com/DYAI2025/ME_CORE_Backend-mar-spar.git
cd ME_CORE_Backend-mar-spar

# Backend-Dependencies installieren
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Frontend-Dependencies installieren
cd ../frontend
npm install

# Spark NLP Setup
cd ../spark-nlp
pip install -r requirements-spark.txt
```

### Entwicklungsumgebung starten

```bash
# Mit Docker Compose (empfohlen)
docker-compose up

# Oder manuell:
# Terminal 1: Backend
cd backend && uvicorn app.main:app --reload

# Terminal 2: Frontend
cd frontend && npm run dev

# Terminal 3: Spark (optional)
cd spark-nlp && spark-submit src/main.py
```

## ğŸ”§ Technische Schnittstellen

### REST API Endpoints

- `GET /api/schemas` - Alle Schemas abrufen
- `GET /api/schemas/{schema_id}` - Einzelnes Schema
- `POST /api/schemas` - Neues Schema erstellen
- `POST /api/analyze` - Text analysieren
- `GET /api/health` - Health Check

### Spark UDFs

```python
# In spark-nlp/src/udfs.py definiert:
detect_markers(text: String) -> Array[String]
score_markers(markers: Array[String]) -> Double
```

### Shared Types

TypeScript-Interfaces und Python-Modelle werden in `backend/src/shared/` und `frontend/src/shared/` geteilt.

## ğŸ­ CI/CD mit Jenkins

Jenkins-Pipelines unter `jenkins/`:

- `build-backend` - Backend Tests & Validation
- `build-spark` - Spark Integration Tests
- `build-frontend` - Frontend Build & Tests
- `deploy-staging` - Staging Deployment
- `deploy-production` - Production Deployment

### Pipeline-Status

Dashboard: [Jenkins Blue Ocean](http://jenkins.example.com/blue)

## ğŸ“Š Monitoring

- Health Check: `GET /api/health`
- Prometheus Metrics: `GET /api/metrics`
- Logging: Strukturierte JSON-Logs in `logs/`

## ğŸ§ª Testing

```bash
# Backend Tests
cd backend && pytest

# Frontend Tests
cd frontend && npm test

# Spark Tests
cd spark-nlp && pytest tests/

# End-to-End Tests
npm run test:e2e
```

## ğŸ“š Dokumentation

- [Architektur-Ãœbersicht](docs/ARCHITECTURE.md)
- [API Dokumentation](docs/openapi.yaml)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [Entwickler-Handbuch](docs/DEVELOPER.md)

## ğŸ”„ Release-Prozess

1. Feature-Branch erstellen: `feature/JIRA-123-description`
2. Code entwickeln und testen
3. Pull Request erstellen
4. Code Review & CI-Checks
5. Merge in `develop`
6. Release-Branch: `release/v1.0.0`
7. Deploy to Staging
8. Tests & Approval
9. Merge in `main` & Tag
10. Production Deploy

## ğŸ¤ Contributing

1. Fork das Repository
2. Feature-Branch erstellen
3. Ã„nderungen committen
4. Tests schreiben/anpassen
5. Pull Request Ã¶ffnen

## ğŸ“„ Lizenz

MIT License - siehe [LICENSE](LICENSE)

## ğŸ‘¥ Team

- **Product Owner**: Chief Product Owner
- **Entwicklung**: Claude-Flow Team
- **DevOps**: Jenkins Integration Team

---

**Hinweis**: Dies ist ein Monorepo. Alle Komponenten mÃ¼ssen zusammen releast werden.