# ME_CORE_Backend-mar-spar

**MarkerEngine Core Backend Monorepo** â€“ Dieses Repository bÃ¼ndelt sÃ¤mtliche Kernkomponenten der MarkerEngine.
Es vereint den Python/FastAPIâ€‘Backendâ€‘Dienst, ein Next.js/Node.jsâ€‘Frontend sowie eine Sparkâ€‘NLPâ€‘Anbindung
fÃ¼r skalierbare Sprachverarbeitung. Das Monorepo stellt einen einheitlichen Buildâ€‘, Testâ€‘ und
Deploymentâ€‘Prozess bereit und dient als zentrale Codebasis fÃ¼r das Gesamtsystem.

## ğŸ§  WofÃ¼r ist dieses Repository gedacht?

Die MarkerEngine Ã¼bersetzt natÃ¼rliche Sprache in strukturierte *Marker* und bietet damit die Grundlage fÃ¼r
intelligente Analysen. Dieses Repo enthÃ¤lt:

- **Backend** â€“ FastAPIâ€‘Service mit modularer Architektur (APIâ€‘Router, Serviceâ€‘Layer, Repositories und Infrastruktur).
- **Frontend** â€“ Next.jsâ€‘Dashboard zur Steuerung und Visualisierung der Analyse.
- **Sparkâ€‘NLP** â€“ Pythonâ€‘Module fÃ¼r rechenintensive NLPâ€‘Jobs auf Apache Spark.

Alle Teile sind so aufgebaut, dass sie getrennt entwickelt werden kÃ¶nnen, aber nahtlos zusammenarbeiten.

## ğŸ—ï¸ Monorepo-Struktur

```
/ME_CORE_Backend-mar-spar/
â”‚
â”œâ”€ .github/                # GitHub Actions / Issue-Vorlagen
â”œâ”€ jenkins/                # Jenkins-Pipeline-Definitions
â”œâ”€ docs/                   # Architektur-, API- und Deploy-Dokumentation
â”œâ”€ tools/                  # Hilfsskripte (z.B. Schema-Generator)
â”‚
â”œâ”€ backend/                # Aus _1-_MEWT-backend
â”‚   â”œâ”€ api/                # FastAPI-Router fÃ¼r Analyse & Schemas
â”‚   â”œâ”€ detect/             # Detector-Registry & Module
â”‚   â”œâ”€ scoring/            # Score-Engine & Profile
â”‚   â”œâ”€ calculate/          # Baseline-Calculator
â”‚   â”œâ”€ markers/            # Marker-Definitionen (yaml + json)
â”‚   â””â”€ schemata/           # JSON-Schemas (v2.1 + enhanced master)
â”‚
â”œâ”€ spark-nlp/              # Aus markerengine-spark-nlp
â”‚   â”œâ”€ src/                # Spark-Jobs, UDF-Registrierung
â”‚   â”œâ”€ docker/             # Docker-Definitionen
â”‚   â””â”€ tests/              # Integrationstests fÃ¼r Spark-Pipeline
â”‚
â””â”€ frontend/               # Aus markerengine_frontend
    â”œâ”€ src/                # Next.js-App
    â”œâ”€ public/             # Statische Assets
    â””â”€ tests/              # UI- und API-Stubs-Tests
```

## ğŸ§© FunktionsÃ¼berblick

- **API & Services**: FastAPI-Router im Verzeichnis `backend/api/` liefern Endpunkte zur
  Analyse von Texten, zur Verwaltung von Markern und zum Monitoring. Die zugehÃ¶rigen
  Services kapseln GeschÃ¤ftslogik und greifen Ã¼ber Repositories auf MongoDB oder
  andere Infrastrukturkomponenten zu.
- **Frontend**: Das Next.js-Dashboard unter `frontend/` kommuniziert Ã¼ber die RESTâ€‘API
  mit dem Backend und bietet eine BenutzeroberflÃ¤che fÃ¼r Konfiguration und Monitoring.
- **Sparkâ€‘NLP**: Der Ordner `spark-nlp/` enthÃ¤lt verteilte NLPâ€‘Jobs (z.â€¯B. Markerâ€‘Erkennung),
  die bei Bedarf separat oder im Dockerâ€‘Verbund gestartet werden kÃ¶nnen.
- **End-to-End-Tests**: Unter `tests/e2e` liegt eine Playwrightâ€‘basierte Testumgebung, die
  Backend und Frontend gemeinsam in Docker startet.

## ğŸš€ Quick Start

### Voraussetzungen

- Python 3.10+
- Node.js 18+
- Java 11 (fÃ¼r Spark NLP)
- Docker & Docker Compose
- MongoDB

### Installation

```bash
# Repository klonen
git clone https://github.com/DYAI2025/ME_CORE_Backend-mar-spar.git
cd ME_CORE_Backend-mar-spar

# Backend-Dependencies installieren
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Frontend-Dependencies installieren
cd ../frontend
npm install

# Spark NLP Setup
cd ../spark-nlp
pip install -r requirements-spark.txt
```

### Entwicklungsumgebung starten

```bash
# Mit Docker Compose (empfohlen)
docker-compose up

# Oder manuell:
# Terminal 1: Backend
cd backend && uvicorn app.main:app --reload

# Terminal 2: Frontend
cd frontend && npm run dev

# Terminal 3: Spark (optional)
cd spark-nlp && spark-submit src/main.py
```

## ğŸ”§ Technische Schnittstellen

### REST API Endpoints

- `GET /api/schemas` - Alle Schemas abrufen
- `GET /api/schemas/{schema_id}` - Einzelnes Schema
- `POST /api/schemas` - Neues Schema erstellen
- `POST /api/analyze` - Text analysieren
- `GET /api/health` - Health Check

### Spark UDFs

```python
# In spark-nlp/src/udfs.py definiert:
detect_markers(text: String) -> Array[String]
score_markers(markers: Array[String]) -> Double
```

### Shared Types

TypeScript-Interfaces und Python-Modelle werden in `backend/src/shared/` und `frontend/src/shared/` geteilt.

## ğŸ­ CI/CD mit Jenkins

Jenkins-Pipelines unter `jenkins/`:

- `build-backend` - Backend Tests & Validation
- `build-spark` - Spark Integration Tests
- `build-frontend` - Frontend Build & Tests
- `deploy-staging` - Staging Deployment
- `deploy-production` - Production Deployment

### Pipeline-Status

Dashboard: [Jenkins Blue Ocean](http://jenkins.example.com/blue)

## ğŸ“Š Monitoring

- Health Check: `GET /api/health`
- Prometheus Metrics: `GET /api/metrics`
- Logging: Strukturierte JSON-Logs in `logs/`

## ğŸ§ª Testing

```bash
# Backend Tests
cd backend && pytest

# Frontend Tests
cd frontend && npm test

# Spark Tests
cd spark-nlp && pytest tests/

# End-to-End Tests
npm run test:e2e
```

## ğŸš¨ Troubleshooting

### Fly.io Deployment Issues

**Problem**: App lÃ¤uft nicht / keine IP-Adresse

**Schnelle LÃ¶sung**:
```bash
# Automatischer Fix-Script
./fix-fly-deployment.sh

# Oder manuell:
flyctl status                    # Status prÃ¼fen
flyctl machines start           # Maschinen starten
flyctl scale count 1           # Mindestens 1 Maschine
flyctl deploy                   # Neu deployen falls nÃ¶tig
```

**Weitere Deployment Guides**:
- [Fly.io Deployment Guide](FLY_DEPLOYMENT_GUIDE.md)
- [Deployment Fixes](FLY_DEPLOYMENT_FIXES.md)
- [Reliability Report](backend/DEPLOYMENT_RELIABILITY_REPORT.md)

## ğŸ“š Dokumentation

- [Architektur-Ãœbersicht](docs/ARCHITECTURE.md)
- [API Dokumentation](docs/openapi.yaml)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [Entwickler-Handbuch](docs/DEVELOPER.md)

## ğŸ”„ Release-Prozess

1. Feature-Branch erstellen: `feature/JIRA-123-description`
2. Code entwickeln und testen
3. Pull Request erstellen
4. Code Review & CI-Checks
5. Merge in `develop`
6. Release-Branch: `release/v1.0.0`
7. Deploy to Staging
8. Tests & Approval
9. Merge in `main` & Tag
10. Production Deploy

## ğŸ¤ Contributing

1. Fork das Repository
2. Feature-Branch erstellen
3. Ã„nderungen committen
4. Tests schreiben/anpassen
5. Pull Request Ã¶ffnen

## ğŸ“„ Lizenz

MIT License - siehe [LICENSE](LICENSE)

## ğŸ‘¥ Team

- **Product Owner**: Chief Product Owner
- **Entwicklung**: Claude-Flow Team
- **DevOps**: Jenkins Integration Team

---

**Hinweis**: Dies ist ein Monorepo. Alle Komponenten mÃ¼ssen zusammen releast werden.